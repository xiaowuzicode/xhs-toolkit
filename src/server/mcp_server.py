"""
å°çº¢ä¹¦MCPæœåŠ¡å™¨æ¨¡å—

æä¾›MCPåè®®çš„æœåŠ¡å™¨å®ç°ï¼Œæ”¯æŒAIå®¢æˆ·ç«¯é€šè¿‡MCPåè®®ä¸å°çº¢ä¹¦äº¤äº’
"""

import os
import json
import asyncio
import signal
import sys
import socket
import uuid
import time
from pathlib import Path
from typing import Dict, Any, List, Union, Optional

from dataclasses import dataclass, asdict

from fastmcp import FastMCP

from ..core.config import XHSConfig
from ..core.exceptions import format_error_message, XHSToolkitError
from ..xiaohongshu.client import XHSClient
from ..xiaohongshu.models import XHSNote
from ..utils.logger import get_logger, setup_logger
from ..data import storage_manager, data_scheduler
from ..auth.smart_auth_server import SmartAuthServer, create_smart_auth_server
from .xhs_api_adapter import XhsApiAdapter

logger = get_logger(__name__)


@dataclass
class PublishTask:
    """å‘å¸ƒä»»åŠ¡æ•°æ®ç±»"""
    task_id: str
    status: str  # "pending", "uploading", "filling", "publishing", "completed", "failed"
    note: XHSNote
    progress: int  # 0-100
    message: str
    result: Dict[str, Any] = None
    start_time: float = None
    end_time: float = None

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        data = asdict(self)
        # ç§»é™¤noteå¯¹è±¡ï¼Œé¿å…åºåˆ—åŒ–é—®é¢˜
        if 'note' in data:
            data['note_title'] = self.note.title
            data['note_has_images'] = bool(self.note.images)
            data['note_has_videos'] = bool(self.note.videos)
            del data['note']
        return data


class TaskManager:
    """ä»»åŠ¡ç®¡ç†å™¨"""

    def __init__(self):
        self.tasks: Dict[str, PublishTask] = {}
        self.running_tasks: Dict[str, asyncio.Task] = {}

    def create_task(self, note: XHSNote) -> str:
        """åˆ›å»ºæ–°ä»»åŠ¡"""
        task_id = str(uuid.uuid4())[:8]  # ä½¿ç”¨çŸ­ID
        task = PublishTask(
            task_id=task_id,
            status="pending",
            note=note,
            progress=0,
            message="ä»»åŠ¡å·²åˆ›å»ºï¼Œå‡†å¤‡å¼€å§‹",
            start_time=time.time()
        )
        self.tasks[task_id] = task
        logger.info(f"ğŸ“‹ åˆ›å»ºæ–°ä»»åŠ¡: {task_id} - {note.title}")
        return task_id

    def get_task(self, task_id: str) -> PublishTask:
        """è·å–ä»»åŠ¡"""
        return self.tasks.get(task_id)

    def update_task(self, task_id: str, status: str = None, progress: int = None, message: str = None, result: Dict = None):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        if task_id in self.tasks:
            task = self.tasks[task_id]
            if status:
                task.status = status
            if progress is not None:
                task.progress = progress
            if message:
                task.message = message
            if result:
                task.result = result
            if status in ["completed", "failed"]:
                task.end_time = time.time()
            logger.info(f"ğŸ“‹ æ›´æ–°ä»»åŠ¡ {task_id}: {status} ({progress}%) - {message}")

    def remove_old_tasks(self, max_age_seconds: int = 3600):
        """ç§»é™¤è¶…è¿‡æŒ‡å®šæ—¶é—´çš„æ—§ä»»åŠ¡"""
        current_time = time.time()
        expired_tasks = []
        for task_id, task in self.tasks.items():
            if task.end_time and (current_time - task.end_time) > max_age_seconds:
                expired_tasks.append(task_id)

        for task_id in expired_tasks:
            del self.tasks[task_id]
            if task_id in self.running_tasks:
                self.running_tasks[task_id].cancel()
                del self.running_tasks[task_id]
            logger.info(f"ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸä»»åŠ¡: {task_id}")


class MCPServer:
    """MCPæœåŠ¡å™¨ç®¡ç†å™¨"""

    def __init__(self, config: XHSConfig):
        """
        åˆå§‹åŒ–MCPæœåŠ¡å™¨
        
        Args:
            config: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        self.config = config
        self.xhs_client = XHSClient(config)
        self.mcp = FastMCP("å°çº¢ä¹¦MCPæœåŠ¡å™¨")
        self.task_manager = TaskManager()  # æ·»åŠ ä»»åŠ¡ç®¡ç†å™¨
        self.scheduler_initialized = False  # è°ƒåº¦å™¨åˆå§‹åŒ–æ ‡å¿—
        self.auth_server = create_smart_auth_server(config)  # æ™ºèƒ½è®¤è¯æœåŠ¡å™¨
        self.xhs_api_adapter = XhsApiAdapter(config)  # XHS API é€‚é…å™¨
        self._setup_tools()
        self._setup_resources()
        self._setup_prompts()

    async def _initialize_data_collection(self) -> None:
        """åˆå§‹åŒ–æ•°æ®é‡‡é›†åŠŸèƒ½"""
        if self.scheduler_initialized:
            return  # å·²ç»åˆå§‹åŒ–è¿‡äº†

        try:
            import os
            logger.info("ğŸ“Š åˆå§‹åŒ–æ•°æ®é‡‡é›†åŠŸèƒ½...")

            # æ£€æŸ¥cookiesæ˜¯å¦å­˜åœ¨ï¼Œæ•°æ®é‡‡é›†éœ€è¦ç™»å½•çŠ¶æ€
            cookies = self.xhs_client.cookie_manager.load_cookies()
            if not cookies:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°cookiesæ–‡ä»¶ï¼Œè·³è¿‡æ•°æ®é‡‡é›†åŠŸèƒ½åˆå§‹åŒ–")
                logger.info("ğŸ’¡ æ•°æ®é‡‡é›†éœ€è¦ç™»å½•çŠ¶æ€ï¼Œè¯·å…ˆè¿è¡Œ: python xhs_toolkit.py cookie save")
                self.scheduler_initialized = False
                return

            logger.info(f"âœ… æ£€æµ‹åˆ° {len(cookies)} ä¸ªcookiesï¼Œå¯ä»¥è¿›è¡Œæ•°æ®é‡‡é›†")

            # åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨
            storage_manager.initialize()
            storage_info = storage_manager.get_storage_info()
            logger.info(f"ğŸ’¾ å­˜å‚¨é…ç½®: {storage_info['storage_types']}")

            # æ£€æŸ¥æ˜¯å¦å¯ç”¨è‡ªåŠ¨é‡‡é›†
            enable_auto_collection = os.getenv('ENABLE_AUTO_COLLECTION', 'false').lower() == 'true'

            if enable_auto_collection:
                # åˆå§‹åŒ–è°ƒåº¦å™¨
                data_scheduler.initialize(self.xhs_client)

                # å¯åŠ¨è°ƒåº¦å™¨
                await data_scheduler.start()

                if data_scheduler.is_running():
                    job_info = data_scheduler.get_job_info()
                    logger.info("â° æ•°æ®é‡‡é›†è°ƒåº¦å™¨å·²å¯åŠ¨")

                    # æ˜¾ç¤ºä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
                    if job_info.get('jobs'):
                        for job in job_info['jobs']:
                            next_run = job.get('next_run_time')
                            if next_run:
                                logger.info(f"ğŸ“… ä¸‹æ¬¡é‡‡é›†æ—¶é—´: {next_run}")
                else:
                    logger.warning("âš ï¸ è°ƒåº¦å™¨å¯åŠ¨å¤±è´¥")
            else:
                logger.info("ğŸ“Š è‡ªåŠ¨æ•°æ®é‡‡é›†å·²ç¦ç”¨")

            self.scheduler_initialized = True

        except Exception as e:
            import traceback
            logger.error(f"âŒ æ•°æ®é‡‡é›†åŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.error(f"âŒ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            self.scheduler_initialized = False

    def _setup_tools(self) -> None:
        """è®¾ç½®MCPå·¥å…·"""

        @self.mcp.tool()
        async def test_connection() -> str:
            """
            æµ‹è¯•MCPè¿æ¥æ˜¯å¦æ­£å¸¸
            
            Returns:
                è¿æ¥çŠ¶æ€ä¿¡æ¯
            """
            logger.info("ğŸ§ª æ”¶åˆ°è¿æ¥æµ‹è¯•è¯·æ±‚")
            try:
                import time
                import os
                current_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())

                # æ£€æŸ¥é…ç½®
                config_status = self.config.to_dict()
                config_status["current_time"] = current_time

                # æ·»åŠ æ•°æ®é‡‡é›†çŠ¶æ€
                config_status["data_collection"] = {
                    "scheduler_initialized": self.scheduler_initialized,
                    "auto_collection_enabled": os.getenv('ENABLE_AUTO_COLLECTION', 'false').lower() == 'true',
                    "storage_info": storage_manager.get_storage_info() if self.scheduler_initialized else None
                }

                logger.info(f"âœ… è¿æ¥æµ‹è¯•å®Œæˆ: {config_status}")

                result = {
                    "status": "success",
                    "message": "MCPè¿æ¥æ­£å¸¸ï¼",
                    "config": config_status,
                    "timestamp": current_time
                }

                return json.dumps(result, ensure_ascii=False, indent=2)

            except Exception as e:
                error_msg = f"è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                return error_msg

        @self.mcp.tool()
        async def smart_publish_note(title: str,
                                     content: str,
                                     images: Optional[Union[str, List[str]]] = None,
                                     videos: Optional[Union[str, List[str]]] = None,
                                     topics: Optional[Union[str, List[str]]] = None,
                                     location: str = "", is_commercial: bool = False) -> str:
            """
            å‘å¸ƒå°çº¢ä¹¦ç¬”è®°ï¼ˆæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼ï¼‰
            
            è¿™æ˜¯ä¸»è¦çš„ç¬”è®°å‘å¸ƒå·¥å…·ï¼Œæ”¯æŒæ›´çµæ´»çš„å‚æ•°è¾“å…¥ï¼Œå¯ä»¥å¤„ç†æ¥è‡ªä¸åŒå¹³å°çš„å„ç§æ•°æ®æ ¼å¼ã€‚
            
            Args:
                title (str): ç¬”è®°æ ‡é¢˜
                content (str): ç¬”è®°å†…å®¹  
                images: å›¾ç‰‡ï¼Œæ”¯æŒæ ¼å¼ï¼š
                       - æœ¬åœ°è·¯å¾„ï¼š"image.jpg" æˆ– ["/path/to/image.jpg"]
                       - ç½‘ç»œåœ°å€ï¼š"https://example.com/image.jpg"
                       - æ··åˆæ•°ç»„ï¼š["local.jpg", "https://example.com/img.jpg"]
                       - é€—å·åˆ†éš”å­—ç¬¦ä¸²ï¼š"a.jpg,b.jpg,c.jpg"
                videos: è§†é¢‘è·¯å¾„ï¼ˆç›®å‰ä»…æ”¯æŒæœ¬åœ°æ–‡ä»¶ï¼‰
                topics: è¯é¢˜ï¼Œæ”¯æŒå­—ç¬¦ä¸²æˆ–æ•°ç»„æ ¼å¼
                        ä¾‹å¦‚ "è¯é¢˜1,è¯é¢˜2" æˆ– ["è¯é¢˜1", "è¯é¢˜2"]
                location (str, optional): ä½ç½®ä¿¡æ¯
                is_commercial (boolean): æ˜¯å¦ä¸ºå•†ä¸šç¬”è®°
            
            Returns:
                str: ä»»åŠ¡IDå’ŒçŠ¶æ€ä¿¡æ¯
                
            ç¤ºä¾‹:
                # ä½¿ç”¨ç½‘ç»œå›¾ç‰‡
                smart_publish_note(
                    title="ç¾é£Ÿåˆ†äº«",
                    content="ä»Šå¤©çš„ç¾é£Ÿ",
                    images="a.jpg,b.jpg,c.jpg"
                    topics="è¯é¢˜1,è¯é¢˜2"
                )
                
            """
            logger.info(f"ğŸš€ å¯åŠ¨å‘å¸ƒä»»åŠ¡: æ ‡é¢˜='{title}'")
            logger.debug(f"ğŸ“‹ å‚æ•°è¯¦æƒ…: images={images}, videos={videos}, topics={topics}")

            try:
                # ä½¿ç”¨å¼‚æ­¥æ™ºèƒ½åˆ›å»ºæ–¹æ³•
                note = await XHSNote.async_smart_create(
                    title=title,
                    content=content,
                    topics=topics,
                    location=location,
                    images=images,
                    videos=videos,
                    is_commercial=is_commercial
                )

                # è®°å½•è§£æç»“æœ
                logger.info(
                    f"âœ… æ™ºèƒ½è§£æç»“æœ: å›¾ç‰‡{len(note.images) if note.images else 0}å¼ , è§†é¢‘{len(note.videos) if note.videos else 0}ä¸ª, è¯é¢˜{len(note.topics) if note.topics else 0}ä¸ª")

                # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
                task_id = self.task_manager.create_task(note)

                # å¯åŠ¨åå°ä»»åŠ¡
                async_task = asyncio.create_task(self._execute_publish_task(task_id))
                self.task_manager.running_tasks[task_id] = async_task

                result = {
                    "success": True,
                    "task_id": task_id,
                    "message": f"å‘å¸ƒä»»åŠ¡å·²å¯åŠ¨ï¼Œä»»åŠ¡ID: {task_id}",
                    "next_step": f"è¯·ä½¿ç”¨ check_task_status('{task_id}') æŸ¥çœ‹è¿›åº¦",
                    "parsing_result": {
                        "images_parsed": note.images if note.images else [],
                        "videos_parsed": note.videos if note.videos else [],
                        "topics_parsed": note.topics if note.topics else [],
                        "images_count": len(note.images) if note.images else 0,
                        "videos_count": len(note.videos) if note.videos else 0,
                        "topics_count": len(note.topics) if note.topics else 0,
                        "content_type": "å›¾æ–‡" if note.images else "è§†é¢‘" if note.videos else "çº¯æ–‡æœ¬"
                    }
                }

                return json.dumps(result, ensure_ascii=False, indent=2)

            except Exception as e:
                error_msg = f"å‘å¸ƒä»»åŠ¡å¯åŠ¨å¤±è´¥: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                return json.dumps({
                    "success": False,
                    "message": error_msg,
                    "suggestion": "è¯·æ£€æŸ¥è¾“å…¥æ ¼å¼ï¼Œç¡®ä¿å›¾ç‰‡/è§†é¢‘è·¯å¾„æ­£ç¡®æˆ–ç½‘ç»œè¿æ¥æ­£å¸¸"
                }, ensure_ascii=False, indent=2)

        @self.mcp.tool()
        async def check_task_status(task_id: str) -> str:
            """
            æ£€æŸ¥å‘å¸ƒä»»åŠ¡çŠ¶æ€
            
            Args:
                task_id (str): ä»»åŠ¡ID
            
            Returns:
                str: ä»»åŠ¡çŠ¶æ€ä¿¡æ¯
            """
            logger.info(f"ğŸ“Š æ£€æŸ¥ä»»åŠ¡çŠ¶æ€: {task_id}")

            task = self.task_manager.get_task(task_id)
            if not task:
                return json.dumps({
                    "success": False,
                    "message": f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨"
                }, ensure_ascii=False, indent=2)

            # è®¡ç®—è¿è¡Œæ—¶é—´
            elapsed_time = 0
            if task.start_time:
                elapsed_time = int(time.time() - task.start_time)

            result = {
                "success": True,
                "task_id": task_id,
                "status": task.status,
                "progress": task.progress,
                "message": task.message,
                "elapsed_seconds": elapsed_time,
                "is_completed": task.status in ["completed", "failed"]
            }

            # å¦‚æœä»»åŠ¡å®Œæˆï¼ŒåŒ…å«ç»“æœ
            if task.result:
                result["result"] = task.result

            return json.dumps(result, ensure_ascii=False, indent=2)

        @self.mcp.tool()
        async def get_task_result(task_id: str) -> str:
            """
            è·å–å·²å®Œæˆä»»åŠ¡çš„ç»“æœ
            
            Args:
                task_id (str): ä»»åŠ¡ID
            
            Returns:
                str: ä»»åŠ¡ç»“æœä¿¡æ¯
            """
            logger.info(f"ğŸ“‹ è·å–ä»»åŠ¡ç»“æœ: {task_id}")

            task = self.task_manager.get_task(task_id)
            if not task:
                return json.dumps({
                    "success": False,
                    "message": f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨"
                }, ensure_ascii=False, indent=2)

            if task.status not in ["completed", "failed"]:
                return json.dumps({
                    "success": False,
                    "message": f"ä»»åŠ¡ {task_id} å°šæœªå®Œæˆï¼Œå½“å‰çŠ¶æ€: {task.status}",
                    "current_status": task.status,
                    "progress": task.progress
                }, ensure_ascii=False, indent=2)

            # è¿”å›å®Œæ•´ç»“æœ
            result = {
                "success": task.status == "completed",
                "task_id": task_id,
                "status": task.status,
                "message": task.message,
                "execution_time": int(task.end_time - task.start_time) if task.end_time and task.start_time else 0
            }

            if task.result:
                result["publish_result"] = task.result

            return json.dumps(result, ensure_ascii=False, indent=2)

        @self.mcp.tool()
        async def login_xiaohongshu(force_relogin: bool = False, quick_mode: bool = False) -> str:
            """
            æ™ºèƒ½ç™»å½•å°çº¢ä¹¦
            
            å½“ç”¨æˆ·è¯´"ç™»å½•å°çº¢ä¹¦"æ—¶è°ƒç”¨æ­¤å·¥å…·ã€‚æä¾›MCPä¸“ç”¨çš„æ™ºèƒ½æµç¨‹ï¼Œæ— éœ€ç”¨æˆ·äº¤äº’ç¡®è®¤ã€‚
            
            Args:
                force_relogin: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç™»å½•ï¼Œå³ä½¿å½“å‰çŠ¶æ€æœ‰æ•ˆ
                quick_mode: å¿«é€Ÿæ¨¡å¼ï¼Œé™ä½éªŒè¯è¦æ±‚ä»¥é¿å…è¶…æ—¶
                
            Returns:
                ç™»å½•ç»“æœçš„JSONå­—ç¬¦ä¸²
            """
            logger.info(f"ğŸš€ MCPå·¥å…·è°ƒç”¨ï¼šæ™ºèƒ½å°çº¢ä¹¦ (force_relogin={force_relogin}, quick_mode={quick_mode})")

            try:
                # å¦‚æœæ˜¯å¿«é€Ÿæ¨¡å¼ï¼Œå…ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰cookies
                if quick_mode:
                    cookies_file = Path(self.config.cookies_file)
                    if cookies_file.exists():
                        logger.info("âš¡ å¿«é€Ÿæ¨¡å¼ï¼šå‘ç°å·²æœ‰cookiesï¼Œè·³è¿‡ç™»å½•")
                        return json.dumps({
                            "success": True,
                            "message": "âœ… å¿«é€Ÿæ¨¡å¼ï¼šæ£€æµ‹åˆ°å·²æœ‰cookiesï¼Œè·³è¿‡ç™»å½•æµç¨‹",
                            "action": "quick_skip",
                            "status": "valid",
                            "mode": "mcp_quick"
                        }, ensure_ascii=False, indent=2)

                # ä½¿ç”¨MCPä¸“ç”¨çš„æ™ºèƒ½æ¨¡å¼
                result = await self.auth_server.smart_login(interactive=False, mcp_mode=True)

                # æ ¼å¼åŒ–è¿”å›æ¶ˆæ¯
                if result.get("success", False):
                    action = result.get("action", "unknown")
                    if action == "mcp_auto_login":
                        message = f"âœ… {result['message']}\nğŸ¤– MCPæ™ºèƒ½ç™»å½•å·²å®Œæˆï¼Œcookieså·²ä¿å­˜"
                    elif action == "skipped":
                        message = f"âœ… {result['message']}\nğŸ’¡ å½“å‰ç™»å½•çŠ¶æ€æœ‰æ•ˆ"
                    else:
                        message = f"âœ… {result['message']}"
                else:
                    message = f"âŒ {result['message']}\nğŸ”§ è¯·æ£€æŸ¥æµè§ˆå™¨æˆ–ç½‘ç»œè¿æ¥"

                logger.info(f"âœ… MCPè‡ªåŠ¨ç™»å½•ç»“æœ: {result.get('action', 'unknown')}")
                return json.dumps({
                    "success": result.get("success", False),
                    "message": message,
                    "action": result.get("action", "unknown"),
                    "status": result.get("status", "unknown"),
                    "mode": "mcp_auto"
                }, ensure_ascii=False, indent=2)

            except Exception as e:
                error_msg = f"MCPè‡ªåŠ¨ç™»å½•æ‰§è¡Œå¤±è´¥: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                return json.dumps({
                    "success": False,
                    "message": f"âŒ {error_msg}",
                    "error": str(e),
                    "mode": "mcp_auto",
                    "suggestion": "å¯ä»¥å°è¯•å¿«é€Ÿæ¨¡å¼ï¼šlogin_xiaohongshu(quick_mode=True)"
                }, ensure_ascii=False, indent=2)

        @self.mcp.tool()
        async def get_creator_data_analysis() -> str:
            """
            è·å–åˆ›ä½œè€…æ•°æ®ç”¨äºåˆ†æ
            
            Returns:
                str: åŒ…å«æ‰€æœ‰åˆ›ä½œè€…æ•°æ®çš„è¯¦ç»†ä¿¡æ¯ç”¨äºæ•°æ®åˆ†æ
            """
            logger.info("ğŸ“Š è·å–åˆ›ä½œè€…æ•°æ®ç”¨äºåˆ†æ")

            try:
                # æ£€æŸ¥cookiesæ˜¯å¦å­˜åœ¨ï¼Œæ•°æ®åˆ†æéœ€è¦ç™»å½•çŠ¶æ€
                cookies = self.xhs_client.cookie_manager.load_cookies()
                if not cookies:
                    return json.dumps({
                        "success": False,
                        "message": "æ•°æ®åˆ†æéœ€è¦ç™»å½•çŠ¶æ€ï¼Œæœªæ‰¾åˆ°cookiesæ–‡ä»¶",
                        "suggestion": "è¯·å…ˆè¿è¡Œ: python xhs_toolkit.py cookie save"
                    }, ensure_ascii=False, indent=2)

                if not self.scheduler_initialized:
                    return json.dumps({
                        "success": False,
                        "message": "æ•°æ®é‡‡é›†åŠŸèƒ½æœªåˆå§‹åŒ–ï¼Œå¯èƒ½å› ä¸ºcookiesé—®é¢˜",
                        "suggestion": "è¯·æ£€æŸ¥cookiesçŠ¶æ€å¹¶é‡å¯æœåŠ¡å™¨"
                    }, ensure_ascii=False, indent=2)

                # è·å–å­˜å‚¨ç®¡ç†å™¨
                csv_storage = storage_manager.get_csv_storage()

                # è¯»å–æ‰€æœ‰æ•°æ®
                dashboard_data = await csv_storage.get_latest_data('dashboard', limit=100)
                content_data = await csv_storage.get_latest_data('content_analysis', limit=100)
                fans_data = await csv_storage.get_latest_data('fans', limit=100)

                # è·å–å­˜å‚¨ä¿¡æ¯
                storage_info = storage_manager.get_storage_info()

                result = {
                    "success": True,
                    "message": "åˆ›ä½œè€…æ•°æ®è·å–æˆåŠŸï¼Œå¯ç”¨äºåˆ†æ",
                    "data_summary": {
                        "dashboard_records": len(dashboard_data),
                        "content_records": len(content_data),
                        "fans_records": len(fans_data),
                        "storage_info": storage_info
                    },
                    "dashboard_data": dashboard_data,
                    "content_analysis_data": content_data,
                    "fans_data": fans_data,
                    "analysis_tips": {
                        "dashboard": "ä»ªè¡¨æ¿æ•°æ®åŒ…å«è´¦å·æ•´ä½“è¡¨ç°æŒ‡æ ‡",
                        "content": "å†…å®¹åˆ†ææ•°æ®åŒ…å«æ¯ç¯‡ç¬”è®°çš„è¯¦ç»†è¡¨ç°",
                        "fans": "ç²‰ä¸æ•°æ®åŒ…å«ç²‰ä¸å¢é•¿è¶‹åŠ¿"
                    },
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
                }

                return json.dumps(result, ensure_ascii=False, indent=2)

            except Exception as e:
                error_msg = f"è·å–åˆ›ä½œè€…æ•°æ®å¤±è´¥: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                return json.dumps({
                    "success": False,
                    "message": error_msg
                }, ensure_ascii=False, indent=2)

        @self.mcp.tool()
        async def parse_xiaohongshu_url(url: str, include_raw_html: bool = False) -> str:
            """
            è§£æå°çº¢ä¹¦URLï¼Œæå–é¡µé¢å†…å®¹ä¿¡æ¯
            
            æ”¯æŒè§£æå°çº¢ä¹¦çš„å„ç§é¡µé¢ç±»å‹ï¼šç¬”è®°é¡µé¢ã€ç”¨æˆ·ä¸»é¡µç­‰ï¼Œæå–å…¶ä¸­çš„æ–‡æœ¬å†…å®¹ã€å›¾ç‰‡ã€ä½œè€…ä¿¡æ¯ç­‰ç»“æ„åŒ–æ•°æ®ã€‚
            
            Args:
                url (str): å°çº¢ä¹¦é¡µé¢URLï¼Œæ”¯æŒæ ¼å¼ï¼š
                          - ç¬”è®°é“¾æ¥ï¼šhttps://www.xiaohongshu.com/explore/...
                          - ç”¨æˆ·ä¸»é¡µï¼šhttps://www.xiaohongshu.com/user/profile/...
                          - å…¶ä»–å°çº¢ä¹¦é¡µé¢URL
                include_raw_html (bool): æ˜¯å¦åœ¨ç»“æœä¸­åŒ…å«åŸå§‹HTMLå†…å®¹ï¼ˆç”¨äºè°ƒè¯•ï¼Œé»˜è®¤Falseï¼‰
            
            Returns:
                str: è§£æç»“æœçš„JSONå­—ç¬¦ä¸²ï¼ŒåŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
                    - success: è§£ææ˜¯å¦æˆåŠŸ
                    - url: åŸå§‹URL
                    - page_type: é¡µé¢ç±»å‹ï¼ˆnote/user/topic/unknownï¼‰
                    - title: é¡µé¢æ ‡é¢˜
                    - content: é¡µé¢æ–‡æœ¬å†…å®¹
                    - author: ä½œè€…ä¿¡æ¯
                    - images: å›¾ç‰‡URLåˆ—è¡¨
                    - tags: æ ‡ç­¾/è¯é¢˜åˆ—è¡¨
                    - likes/comments/shares: äº’åŠ¨æ•°æ®
                    - publish_time: å‘å¸ƒæ—¶é—´
                    - error_message: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
                    
            ç¤ºä¾‹:
                parse_xiaohongshu_url("https://www.xiaohongshu.com/explore/...")
                parse_xiaohongshu_url("https://www.xiaohongshu.com/user/profile/...", include_raw_html=True)
            """
            logger.info(f"ğŸ” æ”¶åˆ°URLè§£æè¯·æ±‚: {url}")
            
            try:
                # åŸºæœ¬URLéªŒè¯
                if not url or not isinstance(url, str):
                    return json.dumps({
                        "success": False,
                        "url": url,
                        "error_message": "URLä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯å­—ç¬¦ä¸²"
                    }, ensure_ascii=False, indent=2)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå°çº¢ä¹¦URL
                if "xiaohongshu.com" not in url and "xhslink.com" not in url:
                    return json.dumps({
                        "success": False,
                        "url": url,
                        "error_message": "åªæ”¯æŒè§£æå°çº¢ä¹¦å®˜æ–¹é“¾æ¥ï¼ˆåŒ…å«xiaohongshu.comæˆ–xhslink.comï¼‰"
                    }, ensure_ascii=False, indent=2)
                
                # åˆ›å»ºæ–°çš„å®¢æˆ·ç«¯å®ä¾‹è¿›è¡Œè§£æ
                client = XHSClient(self.config)
                
                # æ‰§è¡ŒURLè§£æ
                result = await client.parse_xiaohongshu_url(url, include_raw_html)
                
                # æ ¼å¼åŒ–è¿”å›ç»“æœ
                response_data = result.to_dict()
                
                # æ·»åŠ è§£æç»Ÿè®¡ä¿¡æ¯
                response_data["parsing_stats"] = {
                    "images_found": len(result.images) if result.images else 0,
                    "tags_found": len(result.tags) if result.tags else 0,
                    "has_author": bool(result.author),
                    "has_content": bool(result.content),
                    "page_type": result.page_type
                }
                
                # æˆåŠŸæ—¥å¿—
                if result.success:
                    logger.info(f"âœ… URLè§£ææˆåŠŸ - ç±»å‹: {result.page_type}, æ ‡é¢˜: {result.title}")
                else:
                    logger.warning(f"âš ï¸ URLè§£æå¤±è´¥: {result.error_message}")
                
                return json.dumps(response_data, ensure_ascii=False, indent=2)
                
            except Exception as e:
                error_msg = f"URLè§£æè¿‡ç¨‹å‡ºé”™: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                return json.dumps({
                    "success": False,
                    "url": url,
                    "error_message": error_msg,
                    "suggestion": "è¯·æ£€æŸ¥URLæ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç¨åé‡è¯•"
                }, ensure_ascii=False, indent=2)

        @self.mcp.tool()
        async def search_notes(keywords: str) -> str:
            """
            æ ¹æ®å…³é”®è¯æœç´¢ç¬”è®°
            
            è¿™ä¸ªå·¥å…·åŸºäºå°çº¢ä¹¦å®˜æ–¹APIå®ç°ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·è¾“å…¥çš„å…³é”®è¯æœç´¢ç›¸å…³çš„ç¬”è®°å†…å®¹ã€‚
            æœç´¢ç»“æœåŒ…æ‹¬ç¬”è®°æ ‡é¢˜ã€ç‚¹èµæ•°ã€é“¾æ¥ç­‰ä¿¡æ¯ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿæ‰¾åˆ°æ„Ÿå…´è¶£çš„å†…å®¹ã€‚
            
            Args:
                keywords (str): æœç´¢å…³é”®è¯ï¼Œä¾‹å¦‚ï¼š"ç¾é£Ÿæ¨è"ã€"æŠ¤è‚¤å¿ƒå¾—"ã€"æ—…è¡Œæ”»ç•¥"ç­‰
            
            Returns:
                str: æœç´¢ç»“æœçš„JSONå­—ç¬¦ä¸²ï¼ŒåŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
                    - success: æœç´¢æ˜¯å¦æˆåŠŸ
                    - message: ç»“æœæè¿°ä¿¡æ¯
                    - results: æœç´¢ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªç»“æœåŒ…å«ï¼š
                        * title: ç¬”è®°æ ‡é¢˜
                        * liked_count: ç‚¹èµæ•°
                        * url: ç¬”è®°é“¾æ¥ï¼ˆåŒ…å«xsec_tokenï¼‰
                        * index: ç»“æœåºå·
                    - total_count: æœç´¢ç»“æœæ€»æ•°
                    - error_message: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
                        
            ç¤ºä¾‹:
                search_notes("ç¾é£Ÿæ¨è")
                search_notes("æŠ¤è‚¤å¿ƒå¾—")
            """
            logger.info(f"ğŸ” æ”¶åˆ°æœç´¢ç¬”è®°è¯·æ±‚: {keywords}")
            
            try:
                # åŸºæœ¬å‚æ•°éªŒè¯
                if not keywords or not isinstance(keywords, str):
                    return json.dumps({
                        "success": False,
                        "message": "æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯å­—ç¬¦ä¸²",
                        "error_message": "æ— æ•ˆçš„æœç´¢å‚æ•°"
                    }, ensure_ascii=False, indent=2)
                
                keywords = keywords.strip()
                if len(keywords) == 0:
                    return json.dumps({
                        "success": False,
                        "message": "æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º",
                        "error_message": "æœç´¢å…³é”®è¯ä¸ºç©º"
                    }, ensure_ascii=False, indent=2)
                
                # è°ƒç”¨APIæœç´¢
                data = await self.xhs_api_adapter.search_notes(keywords)
                
                # å¤„ç†æœç´¢ç»“æœ
                results = []
                if 'data' in data and 'items' in data['data'] and len(data['data']['items']) > 0:
                    for i, item in enumerate(data['data']['items']):
                        if 'note_card' in item and 'display_title' in item['note_card']:
                            title = item['note_card']['display_title']
                            liked_count = item['note_card']['interact_info']['liked_count']
                            url = f'https://www.xiaohongshu.com/explore/{item["id"]}?xsec_token={item["xsec_token"]}'
                            
                            results.append({
                                "index": i,
                                "title": title,
                                "liked_count": liked_count,
                                "url": url
                            })
                    
                    # æˆåŠŸæ‰¾åˆ°ç»“æœ
                    result_data = {
                        "success": True,
                        "message": f"æˆåŠŸæ‰¾åˆ° {len(results)} æ¡ä¸ã€Œ{keywords}ã€ç›¸å…³çš„ç¬”è®°",
                        "keywords": keywords,
                        "results": results,
                        "total_count": len(results)
                    }
                    
                    logger.info(f"âœ… æœç´¢å®Œæˆ: {keywords} - æ‰¾åˆ°{len(results)}æ¡ç»“æœ")
                    return json.dumps(result_data, ensure_ascii=False, indent=2)
                else:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯cookieé—®é¢˜
                    cookie_status = await self.xhs_api_adapter.check_cookie()
                    if "æœ‰æ•ˆ" in cookie_status:
                        # Cookieæœ‰æ•ˆä½†æ²¡æ‰¾åˆ°ç»“æœ
                        result_data = {
                            "success": True,
                            "message": f"æœªæ‰¾åˆ°ä¸ã€Œ{keywords}ã€ç›¸å…³çš„ç¬”è®°",
                            "keywords": keywords,
                            "results": [],
                            "total_count": 0
                        }
                    else:
                        # Cookieæ— æ•ˆ
                        result_data = {
                            "success": False,
                            "message": "æœç´¢å¤±è´¥ï¼šç™»å½•çŠ¶æ€æ— æ•ˆ",
                            "keywords": keywords,
                            "error_message": "éœ€è¦é‡æ–°ç™»å½•å°çº¢ä¹¦",
                            "suggestion": "è¯·å…ˆè¿è¡Œç™»å½•å·¥å…·ï¼šlogin_xiaohongshu()"
                        }
                    
                    logger.warning(f"âš ï¸ æœç´¢æ— ç»“æœæˆ–Cookieå¤±æ•ˆ: {keywords}")
                    return json.dumps(result_data, ensure_ascii=False, indent=2)
                    
            except Exception as e:
                error_msg = f"æœç´¢ç¬”è®°è¿‡ç¨‹å‡ºé”™: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                return json.dumps({
                    "success": False,
                    "message": "æœç´¢ç¬”è®°å¤±è´¥",
                    "keywords": keywords,
                    "error_message": error_msg,
                    "suggestion": "è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•"
                }, ensure_ascii=False, indent=2)

        @self.mcp.tool()
        async def get_note_content(url: str) -> str:
            """
            è·å–ç¬”è®°å†…å®¹ï¼Œå‚æ•°urlè¦å¸¦ä¸Šxsec_token
            
            è¿™ä¸ªå·¥å…·å¯ä»¥è·å–æŒ‡å®šå°çº¢ä¹¦ç¬”è®°çš„è¯¦ç»†å†…å®¹ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€ä½œè€…ä¿¡æ¯ã€å‘å¸ƒæ—¶é—´ã€
            äº’åŠ¨æ•°æ®ï¼ˆç‚¹èµã€è¯„è®ºã€æ”¶è—ï¼‰ä»¥åŠç¬”è®°æ­£æ–‡å†…å®¹ã€‚éœ€è¦æä¾›åŒ…å«xsec_tokençš„å®Œæ•´URLã€‚
            
            Args:
                url (str): ç¬”è®°URLï¼Œå¿…é¡»åŒ…å«xsec_tokenå‚æ•°
                          æ ¼å¼ï¼šhttps://www.xiaohongshu.com/explore/{note_id}?xsec_token={token}
                          å¯ä»¥ä»search_notesçš„ç»“æœä¸­è·å–æ­¤æ ¼å¼çš„URL
            
            Returns:
                str: ç¬”è®°å†…å®¹çš„JSONå­—ç¬¦ä¸²ï¼ŒåŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
                    - success: è·å–æ˜¯å¦æˆåŠŸ
                    - message: ç»“æœæè¿°ä¿¡æ¯
                    - note_info: ç¬”è®°ä¿¡æ¯ï¼ˆå¦‚æœæˆåŠŸï¼‰ï¼ŒåŒ…å«ï¼š
                        * title: ç¬”è®°æ ‡é¢˜
                        * author: ä½œè€…æ˜µç§°
                        * publish_time: å‘å¸ƒæ—¶é—´
                        * liked_count: ç‚¹èµæ•°
                        * comment_count: è¯„è®ºæ•°
                        * collected_count: æ”¶è—æ•°
                        * content: ç¬”è®°æ­£æ–‡å†…å®¹
                        * cover_image: å°é¢å›¾ç‰‡URL
                        * url: ç¬”è®°é“¾æ¥
                    - error_message: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
                        
            ç¤ºä¾‹:
                get_note_content("https://www.xiaohongshu.com/explore/123456?xsec_token=abc123")
            """
            logger.info(f"ğŸ“„ æ”¶åˆ°è·å–ç¬”è®°å†…å®¹è¯·æ±‚: {url}")
            
            try:
                # åŸºæœ¬URLéªŒè¯
                if not url or not isinstance(url, str):
                    return json.dumps({
                        "success": False,
                        "message": "URLä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯å­—ç¬¦ä¸²",
                        "error_message": "æ— æ•ˆçš„URLå‚æ•°"
                    }, ensure_ascii=False, indent=2)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå°çº¢ä¹¦URL
                if "xiaohongshu.com" not in url and "xhslink.com" not in url:
                    return json.dumps({
                        "success": False,
                        "message": "åªæ”¯æŒå°çº¢ä¹¦å®˜æ–¹é“¾æ¥",
                        "url": url,
                        "error_message": "URLå¿…é¡»åŒ…å«xiaohongshu.comæˆ–xhslink.com"
                    }, ensure_ascii=False, indent=2)
                
                # æå–note_idå’Œxsec_token
                params = self.xhs_api_adapter.get_nodeid_token(url=url)
                note_id = params.get("note_id")
                xsec_token = params.get("xsec_token")
                
                if not note_id:
                    return json.dumps({
                        "success": False,
                        "message": "æ— æ³•ä»URLä¸­æå–ç¬”è®°ID",
                        "url": url,
                        "error_message": "URLæ ¼å¼ä¸æ­£ç¡®"
                    }, ensure_ascii=False, indent=2)
                
                if not xsec_token:
                    return json.dumps({
                        "success": False,
                        "message": "URLä¸­ç¼ºå°‘xsec_tokenå‚æ•°",
                        "url": url,
                        "error_message": "éœ€è¦åŒ…å«xsec_tokençš„å®Œæ•´URL",
                        "suggestion": "è¯·ä½¿ç”¨search_notesè·å–åŒ…å«xsec_tokençš„URL"
                    }, ensure_ascii=False, indent=2)
                
                # è°ƒç”¨APIè·å–ç¬”è®°å†…å®¹
                data = await self.xhs_api_adapter.get_note_content(note_id, xsec_token)
                
                # å¤„ç†è¿”å›ç»“æœ
                if 'data' in data and 'items' in data['data'] and len(data['data']['items']) > 0:
                    item = data['data']['items'][0]
                    
                    if 'note_card' in item and 'user' in item['note_card']:
                        note_card = item['note_card']
                        
                        # æå–å°é¢å›¾ç‰‡
                        cover = ''
                        if 'image_list' in note_card and len(note_card['image_list']) > 0:
                            if note_card['image_list'][0].get('url_pre'):
                                cover = note_card['image_list'][0]['url_pre']
                        
                        # æ ¼å¼åŒ–å‘å¸ƒæ—¶é—´
                        publish_time = "æœªçŸ¥æ—¶é—´"
                        if note_card.get('time'):
                            try:
                                timestamp = note_card.get('time', 0) / 1000
                                publish_time = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')
                            except:
                                publish_time = "æ—¶é—´æ ¼å¼é”™è¯¯"
                        
                        # æå–äº’åŠ¨æ•°æ®
                        interact_info = note_card.get('interact_info', {})
                        liked_count = interact_info.get('liked_count', 0)
                        comment_count = interact_info.get('comment_count', 0)
                        collected_count = interact_info.get('collected_count', 0)
                        
                        # æ„å»ºç¬”è®°ä¿¡æ¯
                        note_info = {
                            "title": note_card.get('title', ''),
                            "author": note_card['user'].get('nickname', ''),
                            "publish_time": publish_time,
                            "liked_count": liked_count,
                            "comment_count": comment_count,
                            "collected_count": collected_count,
                            "content": note_card.get('desc', ''),
                            "cover_image": cover,
                            "url": url
                        }
                        
                        result_data = {
                            "success": True,
                            "message": f"æˆåŠŸè·å–ç¬”è®°å†…å®¹ï¼š{note_info['title']}",
                            "note_info": note_info
                        }
                        
                        logger.info(f"âœ… è·å–ç¬”è®°å†…å®¹æˆåŠŸ: {note_info['title']}")
                        return json.dumps(result_data, ensure_ascii=False, indent=2)
                    else:
                        logger.warning("âš ï¸ è¿”å›æ•°æ®ç»“æ„å¼‚å¸¸")
                        return json.dumps({
                            "success": False,
                            "message": "ç¬”è®°æ•°æ®ç»“æ„å¼‚å¸¸",
                            "url": url,
                            "error_message": "APIè¿”å›æ•°æ®æ ¼å¼ä¸æ­£ç¡®"
                        }, ensure_ascii=False, indent=2)
                else:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯cookieé—®é¢˜
                    cookie_status = await self.xhs_api_adapter.check_cookie()
                    if "æœ‰æ•ˆ" in cookie_status:
                        error_msg = "è·å–ç¬”è®°å†…å®¹å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç¬”è®°ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤"
                    else:
                        error_msg = "è·å–ç¬”è®°å†…å®¹å¤±è´¥ï¼šç™»å½•çŠ¶æ€æ— æ•ˆ"
                    
                    logger.warning(f"âš ï¸ è·å–ç¬”è®°å†…å®¹å¤±è´¥: {url}")
                    return json.dumps({
                        "success": False,
                        "message": error_msg,
                        "url": url,
                        "error_message": "æ— æ³•è·å–ç¬”è®°å†…å®¹",
                        "suggestion": "è¯·æ£€æŸ¥URLæ˜¯å¦æ­£ç¡®æˆ–é‡æ–°ç™»å½•"
                    }, ensure_ascii=False, indent=2)
                    
            except Exception as e:
                error_msg = f"è·å–ç¬”è®°å†…å®¹è¿‡ç¨‹å‡ºé”™: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                return json.dumps({
                    "success": False,
                    "message": "è·å–ç¬”è®°å†…å®¹å¤±è´¥",
                    "url": url,
                    "error_message": error_msg,
                    "suggestion": "è¯·æ£€æŸ¥URLæ ¼å¼å’Œç½‘ç»œè¿æ¥"
                }, ensure_ascii=False, indent=2)

        @self.mcp.tool()
        async def get_note_comments(url: str) -> str:
            """
            è·å–ç¬”è®°è¯„è®ºï¼Œå‚æ•°urlè¦å¸¦ä¸Šxsec_token
            
            è¿™ä¸ªå·¥å…·å¯ä»¥è·å–æŒ‡å®šå°çº¢ä¹¦ç¬”è®°çš„è¯„è®ºåˆ—è¡¨ï¼ŒåŒ…æ‹¬è¯„è®ºå†…å®¹ã€è¯„è®ºè€…ä¿¡æ¯å’Œå‘å¸ƒæ—¶é—´ã€‚
            éœ€è¦æä¾›åŒ…å«xsec_tokençš„å®Œæ•´URLã€‚
            
            Args:
                url (str): ç¬”è®°URLï¼Œå¿…é¡»åŒ…å«xsec_tokenå‚æ•°
                          æ ¼å¼ï¼šhttps://www.xiaohongshu.com/explore/{note_id}?xsec_token={token}
                          å¯ä»¥ä»search_notesçš„ç»“æœä¸­è·å–æ­¤æ ¼å¼çš„URL
            
            Returns:
                str: è¯„è®ºæ•°æ®çš„JSONå­—ç¬¦ä¸²ï¼ŒåŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
                    - success: è·å–æ˜¯å¦æˆåŠŸ
                    - message: ç»“æœæè¿°ä¿¡æ¯
                    - comments: è¯„è®ºåˆ—è¡¨ï¼ˆå¦‚æœæˆåŠŸï¼‰ï¼Œæ¯ä¸ªè¯„è®ºåŒ…å«ï¼š
                        * index: è¯„è®ºåºå·
                        * author: è¯„è®ºè€…æ˜µç§°
                        * content: è¯„è®ºå†…å®¹
                        * create_time: å‘å¸ƒæ—¶é—´
                    - total_count: è¯„è®ºæ€»æ•°
                    - error_message: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
                        
            ç¤ºä¾‹:
                get_note_comments("https://www.xiaohongshu.com/explore/123456?xsec_token=abc123")
            """
            logger.info(f"ğŸ’¬ æ”¶åˆ°è·å–ç¬”è®°è¯„è®ºè¯·æ±‚: {url}")
            
            try:
                # åŸºæœ¬URLéªŒè¯
                if not url or not isinstance(url, str):
                    return json.dumps({
                        "success": False,
                        "message": "URLä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯å­—ç¬¦ä¸²",
                        "error_message": "æ— æ•ˆçš„URLå‚æ•°"
                    }, ensure_ascii=False, indent=2)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå°çº¢ä¹¦URL
                if "xiaohongshu.com" not in url and "xhslink.com" not in url:
                    return json.dumps({
                        "success": False,
                        "message": "åªæ”¯æŒå°çº¢ä¹¦å®˜æ–¹é“¾æ¥",
                        "url": url,
                        "error_message": "URLå¿…é¡»åŒ…å«xiaohongshu.comæˆ–xhslink.com"
                    }, ensure_ascii=False, indent=2)
                
                # æå–note_idå’Œxsec_token
                params = self.xhs_api_adapter.get_nodeid_token(url=url)
                note_id = params.get("note_id")
                xsec_token = params.get("xsec_token")
                
                if not note_id:
                    return json.dumps({
                        "success": False,
                        "message": "æ— æ³•ä»URLä¸­æå–ç¬”è®°ID",
                        "url": url,
                        "error_message": "URLæ ¼å¼ä¸æ­£ç¡®"
                    }, ensure_ascii=False, indent=2)
                
                if not xsec_token:
                    return json.dumps({
                        "success": False,
                        "message": "URLä¸­ç¼ºå°‘xsec_tokenå‚æ•°",
                        "url": url,
                        "error_message": "éœ€è¦åŒ…å«xsec_tokençš„å®Œæ•´URL",
                        "suggestion": "è¯·ä½¿ç”¨search_notesè·å–åŒ…å«xsec_tokençš„URL"
                    }, ensure_ascii=False, indent=2)
                
                # è°ƒç”¨APIè·å–ç¬”è®°è¯„è®º
                data = await self.xhs_api_adapter.get_note_comments(note_id, xsec_token)
                
                # å¤„ç†è¿”å›ç»“æœ
                comments = []
                if 'data' in data and 'comments' in data['data'] and len(data['data']['comments']) > 0:
                    for i, comment in enumerate(data['data']['comments']):
                        # æ ¼å¼åŒ–è¯„è®ºæ—¶é—´
                        create_time = "æœªçŸ¥æ—¶é—´"
                        if comment.get('create_time'):
                            try:
                                timestamp = comment['create_time'] / 1000
                                create_time = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')
                            except:
                                create_time = "æ—¶é—´æ ¼å¼é”™è¯¯"
                        
                        comment_info = {
                            "index": i,
                            "author": comment['user_info'].get('nickname', 'åŒ¿åç”¨æˆ·'),
                            "content": comment.get('content', ''),
                            "create_time": create_time
                        }
                        
                        comments.append(comment_info)
                    
                    result_data = {
                        "success": True,
                        "message": f"æˆåŠŸè·å–åˆ° {len(comments)} æ¡è¯„è®º",
                        "comments": comments,
                        "total_count": len(comments),
                        "url": url
                    }
                    
                    logger.info(f"âœ… è·å–ç¬”è®°è¯„è®ºæˆåŠŸ: å…±{len(comments)}æ¡è¯„è®º")
                    return json.dumps(result_data, ensure_ascii=False, indent=2)
                else:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯cookieé—®é¢˜
                    cookie_status = await self.xhs_api_adapter.check_cookie()
                    if "æœ‰æ•ˆ" in cookie_status:
                        result_data = {
                            "success": True,
                            "message": "è¯¥ç¬”è®°æš‚æ— è¯„è®º",
                            "comments": [],
                            "total_count": 0,
                            "url": url
                        }
                    else:
                        result_data = {
                            "success": False,
                            "message": "è·å–è¯„è®ºå¤±è´¥ï¼šç™»å½•çŠ¶æ€æ— æ•ˆ",
                            "url": url,
                            "error_message": "éœ€è¦é‡æ–°ç™»å½•å°çº¢ä¹¦",
                            "suggestion": "è¯·å…ˆè¿è¡Œç™»å½•å·¥å…·ï¼šlogin_xiaohongshu()"
                        }
                    
                    logger.info(f"â„¹ï¸ è·å–ç¬”è®°è¯„è®º: æ— è¯„è®ºæˆ–éœ€è¦ç™»å½•")
                    return json.dumps(result_data, ensure_ascii=False, indent=2)
                    
            except Exception as e:
                error_msg = f"è·å–ç¬”è®°è¯„è®ºè¿‡ç¨‹å‡ºé”™: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                return json.dumps({
                    "success": False,
                    "message": "è·å–ç¬”è®°è¯„è®ºå¤±è´¥",
                    "url": url,
                    "error_message": error_msg,
                    "suggestion": "è¯·æ£€æŸ¥URLæ ¼å¼å’Œç½‘ç»œè¿æ¥"
                }, ensure_ascii=False, indent=2)


    async def _execute_publish_task(self, task_id: str) -> None:
        """
        æ‰§è¡Œå‘å¸ƒä»»åŠ¡çš„åå°é€»è¾‘
        
        Args:
            task_id: ä»»åŠ¡ID
        """
        task = self.task_manager.get_task(task_id)
        if not task:
            logger.error(f"âŒ ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
            return

        try:
            # é˜¶æ®µ0ï¼šå¿«é€ŸéªŒè¯ç™»å½•çŠ¶æ€ï¼ˆä»…æ£€æŸ¥cookieså­˜åœ¨æ€§ï¼‰
            self.task_manager.update_task(task_id, status="validating", progress=5, message="æ­£åœ¨å¿«é€ŸéªŒè¯ç™»å½•çŠ¶æ€...")

            try:
                # åªæ£€æŸ¥cookiesæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œé¿å…é‡å¤çš„è¯¦ç»†éªŒè¯
                cookies_file = Path(self.config.cookies_file)
                if not cookies_file.exists():
                    self.task_manager.update_task(
                        task_id,
                        status="failed",
                        progress=0,
                        message="âŒ æœªæ‰¾åˆ°ç™»å½•cookiesï¼Œè¯·å…ˆç™»å½•å°çº¢ä¹¦",
                        result={
                            "success": False,
                            "error_type": "auth_required",
                            "user_action_required": "éœ€è¦ç™»å½•å°çº¢ä¹¦",
                            "suggested_command": "è¯·å¯¹AIè¯´ï¼š'ç™»å½•å°çº¢ä¹¦'"
                        }
                    )
                    logger.warning(f"âš ï¸ ä»»åŠ¡ {task_id} å› ç¼ºå°‘cookiesè€Œåœæ­¢")
                    return

                # å¿«é€ŸéªŒè¯é€šè¿‡ï¼Œç»§ç»­å‘å¸ƒæµç¨‹
                self.task_manager.update_task(task_id, status="initializing", progress=10, message="âœ… ç™»å½•çŠ¶æ€éªŒè¯é€šè¿‡ï¼Œæ­£åœ¨åˆå§‹åŒ–æµè§ˆå™¨...")

            except Exception as e:
                logger.error(f"âŒ ç™»å½•çŠ¶æ€éªŒè¯å‡ºé”™: {e}")
                self.task_manager.update_task(
                    task_id,
                    status="failed",
                    progress=0,
                    message=f"âŒ ç™»å½•çŠ¶æ€éªŒè¯å‡ºé”™: {str(e)}",
                    result={
                        "success": False,
                        "error_type": "validation_error",
                        "error": str(e),
                        "suggested_action": "è¯·é‡æ–°ç™»å½•å°çº¢ä¹¦åé‡è¯•"
                    }
                )
                return

            # é˜¶æ®µ1ï¼šåˆå§‹åŒ–æµè§ˆå™¨
            # åˆ›å»ºæ–°çš„å®¢æˆ·ç«¯å®ä¾‹ï¼Œé¿å…å¹¶å‘å†²çª
            client = XHSClient(self.config)

            # é˜¶æ®µ2ï¼šä¸Šä¼ æ–‡ä»¶
            if task.note.images or task.note.videos:
                self.task_manager.update_task(task_id, status="uploading", progress=20, message="æ­£åœ¨ä¸Šä¼ æ–‡ä»¶...")

                # æ‰§è¡Œå‘å¸ƒè¿‡ç¨‹
                result = await client.publish_note(task.note)

                if result.success:
                    self.task_manager.update_task(
                        task_id,
                        status="completed",
                        progress=100,
                        message="å‘å¸ƒæˆåŠŸï¼",
                        result=result.to_dict()
                    )
                else:
                    self.task_manager.update_task(
                        task_id,
                        status="failed",
                        progress=0,
                        message=f"å‘å¸ƒå¤±è´¥: {result.message}",
                        result=result.to_dict()
                    )
            else:
                # æ²¡æœ‰æ–‡ä»¶çš„å¿«é€Ÿå‘å¸ƒ
                self.task_manager.update_task(task_id, status="publishing", progress=60, message="æ­£åœ¨å‘å¸ƒç¬”è®°...")

                result = await client.publish_note(task.note)

                if result.success:
                    self.task_manager.update_task(
                        task_id,
                        status="completed",
                        progress=100,
                        message="å‘å¸ƒæˆåŠŸï¼",
                        result=result.to_dict()
                    )
                else:
                    self.task_manager.update_task(
                        task_id,
                        status="failed",
                        progress=0,
                        message=f"å‘å¸ƒå¤±è´¥: {result.message}",
                        result=result.to_dict()
                    )

        except Exception as e:
            error_msg = f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"âŒ ä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥: {e}")
            self.task_manager.update_task(
                task_id,
                status="failed",
                progress=0,
                message=error_msg,
                result={"success": False, "message": error_msg}
            )
        finally:
            # æ¸…ç†è¿è¡Œä»»åŠ¡è®°å½•
            if task_id in self.task_manager.running_tasks:
                del self.task_manager.running_tasks[task_id]

    def _setup_resources(self) -> None:
        """è®¾ç½®MCPèµ„æº"""

        @self.mcp.resource("xhs://config")
        def get_xhs_config() -> str:
            """è·å–å°çº¢ä¹¦MCPæœåŠ¡å™¨é…ç½®ä¿¡æ¯"""
            config_info = self.config.to_dict()
            config_info["server_status"] = "running"
            return json.dumps(config_info, ensure_ascii=False, indent=2)

        @self.mcp.resource("xhs://help")
        def get_xhs_help() -> str:
            """è·å–å°çº¢ä¹¦MCPæœåŠ¡å™¨ä½¿ç”¨å¸®åŠ©"""
            help_text = """
# å°çº¢ä¹¦MCPæœåŠ¡å™¨ä½¿ç”¨å¸®åŠ©

## å¯ç”¨å·¥å…·

### 1. test_connection
- åŠŸèƒ½: æµ‹è¯•MCPè¿æ¥
- å‚æ•°: æ— 

### 2. start_publish_task
- åŠŸèƒ½: å¯åŠ¨å¼‚æ­¥å‘å¸ƒä»»åŠ¡ï¼ˆè§£å†³MCPè¶…æ—¶é—®é¢˜ï¼‰
- å‚æ•°:
  - title: ç¬”è®°æ ‡é¢˜
  - content: ç¬”è®°å†…å®¹
  - tags: æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼‰
  - location: ä½ç½®ä¿¡æ¯
  - images: å›¾ç‰‡è·¯å¾„ï¼ˆé€—å·åˆ†éš”å¤šä¸ªè·¯å¾„ï¼‰
  - videos: è§†é¢‘è·¯å¾„ï¼ˆé€—å·åˆ†éš”å¤šä¸ªè·¯å¾„ï¼‰

### 3. check_task_status
- åŠŸèƒ½: æ£€æŸ¥å‘å¸ƒä»»åŠ¡çŠ¶æ€
- å‚æ•°:
  - task_id: ä»»åŠ¡ID

### 4. get_task_result
- åŠŸèƒ½: è·å–å·²å®Œæˆä»»åŠ¡çš„ç»“æœ
- å‚æ•°:
  - task_id: ä»»åŠ¡ID

### 5. close_browser
- åŠŸèƒ½: å…³é—­æµè§ˆå™¨

### 6. test_publish_params
- åŠŸèƒ½: æµ‹è¯•å‘å¸ƒå‚æ•°è§£æï¼ˆè°ƒè¯•ç”¨ï¼‰
- å‚æ•°:
  - title: æµ‹è¯•æ ‡é¢˜
  - content: æµ‹è¯•å†…å®¹
  - image_path: æµ‹è¯•å›¾ç‰‡è·¯å¾„

## å¯ç”¨èµ„æº

- xhs://config - æŸ¥çœ‹æœåŠ¡å™¨é…ç½®
- xhs://help - æŸ¥çœ‹æ­¤å¸®åŠ©ä¿¡æ¯

## ç¯å¢ƒå˜é‡

- CHROME_PATH: Chromeæµè§ˆå™¨è·¯å¾„
- WEBDRIVER_CHROME_DRIVER: ChromeDriverè·¯å¾„
- json_path: Cookiesæ–‡ä»¶è·¯å¾„
"""
            return help_text

    def _setup_prompts(self) -> None:
        """è®¾ç½®MCPæç¤ºè¯"""

        @self.mcp.prompt()
        def xiaohongshu_content_creation(topic: str, style: str = "ç”Ÿæ´»åˆ†äº«") -> str:
            """
            å°çº¢ä¹¦å†…å®¹åˆ›ä½œåŠ©æ‰‹
            
            Args:
                topic: å†…å®¹ä¸»é¢˜
                style: å†™ä½œé£æ ¼ï¼ˆç”Ÿæ´»åˆ†äº«ã€ç¾å¦†æŠ¤è‚¤ã€ç¾é£Ÿæ¢åº—ã€æ—…è¡Œæ”»ç•¥ç­‰ï¼‰
            
            Returns:
                å†…å®¹åˆ›ä½œæç¤ºè¯
            """
            prompt = f"""
è¯·å¸®æˆ‘åˆ›ä½œä¸€ç¯‡å…³äº"{topic}"çš„å°çº¢ä¹¦ç¬”è®°ï¼Œé£æ ¼ä¸º"{style}"ã€‚

è¦æ±‚ï¼š
1. æ ‡é¢˜è¦å¸å¼•äººï¼ŒåŒ…å«emojiå’Œå…³é”®è¯
2. å†…å®¹è¦æœ‰ä»·å€¼ï¼ŒåŒ…å«å…·ä½“çš„å»ºè®®æˆ–ä¿¡æ¯
3. é€‚å½“ä½¿ç”¨emojiè®©å†…å®¹æ›´ç”ŸåŠ¨
4. æ·»åŠ ç›¸å…³æ ‡ç­¾ï¼ˆ3-5ä¸ªï¼‰
5. å­—æ•°æ§åˆ¶åœ¨200-500å­—
6. è¯­è¨€é£æ ¼è¦è´´è¿‘å°çº¢ä¹¦ç”¨æˆ·ä¹ æƒ¯

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

ã€æ ‡é¢˜ã€‘
[åœ¨è¿™é‡Œå†™æ ‡é¢˜]

ã€æ­£æ–‡ã€‘
[åœ¨è¿™é‡Œå†™æ­£æ–‡å†…å®¹]

ã€æ ‡ç­¾ã€‘
[åœ¨è¿™é‡Œåˆ—å‡ºç›¸å…³æ ‡ç­¾]

ã€å‘å¸ƒå»ºè®®ã€‘
[å‘å¸ƒæ—¶é—´ã€é…å›¾å»ºè®®ç­‰]
"""
            return prompt

    def _setup_signal_handlers(self) -> None:
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
        def signal_handler(signum, frame):
            logger.info("ğŸ‘‹ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­æœåŠ¡å™¨...")
            # æ¸…ç†èµ„æº
            try:
                # åœæ­¢æ•°æ®é‡‡é›†è°ƒåº¦å™¨
                if self.scheduler_initialized and data_scheduler.is_running():
                    logger.info("ğŸ§¹ åœæ­¢æ•°æ®é‡‡é›†è°ƒåº¦å™¨...")
                    asyncio.run(data_scheduler.stop())

                # æ¸…ç†æµè§ˆå™¨å®ä¾‹
                if hasattr(self.xhs_client, 'browser_manager') and self.xhs_client.browser_manager.is_initialized:
                    logger.info("ğŸ§¹ æ¸…ç†æ®‹ç•™çš„æµè§ˆå™¨å®ä¾‹...")
                    self.xhs_client.browser_manager.close_driver()
            except Exception as cleanup_error:
                logger.warning(f"âš ï¸ æ¸…ç†èµ„æºæ—¶å‡ºé”™: {cleanup_error}")

            logger.info("âœ… æœåŠ¡å™¨å·²åœæ­¢")
            os._exit(0)  # å¼ºåˆ¶é€€å‡ºé¿å…ASGIé”™è¯¯

        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)

    def start_stdio(self) -> None:
        """å¯åŠ¨stdioæ¨¡å¼çš„MCPæœåŠ¡å™¨ï¼ˆç”¨äºClaude Desktopï¼‰"""
        # è®¾ç½®æ—¥å¿—åªè¾“å‡ºåˆ°stderrï¼Œé¿å…å¹²æ‰°stdioé€šä¿¡
        import sys
        from ..utils.logger import setup_logger, get_logger

        # é‡æ–°é…ç½®æ—¥å¿—ï¼Œåªè¾“å‡ºåˆ°stderr
        import logging
        root_logger = logging.getLogger()
        root_logger.handlers = []

        stderr_handler = logging.StreamHandler(sys.stderr)
        stderr_handler.setFormatter(logging.Formatter('%(asctime)s | %(levelname)-8s | %(message)s'))
        root_logger.addHandler(stderr_handler)
        root_logger.setLevel(getattr(logging, self.config.log_level.upper()))

        logger.info("ğŸš€ å¯åŠ¨MCPæœåŠ¡å™¨ï¼ˆstdioæ¨¡å¼ï¼‰...")

        # éªŒè¯é…ç½®
        validation = self.config.validate_config()
        if not validation["valid"]:
            logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥:")
            for issue in validation["issues"]:
                logger.error(f"   â€¢ {issue}")
            return

        logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")

        # å·¥å…·å·²åœ¨__init__ä¸­æ³¨å†Œ
        logger.info(f"ğŸ¯ MCPå·¥å…·åˆ—è¡¨:")
        for tool in ["test_connection", "smart_publish_note", "check_task_status",
                     "get_task_result", "login_xiaohongshu", "get_creator_data_analysis",
                     "parse_xiaohongshu_url", "search_notes", "get_note_content", "get_note_comments"]:
            logger.info(f"   â€¢ {tool}")

        # åˆå§‹åŒ–æ•°æ®é‡‡é›†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            cookies = self.xhs_client.cookie_manager.load_cookies()
            if cookies and os.getenv('ENABLE_AUTO_COLLECTION', 'false').lower() == 'true':
                logger.info("ğŸ“Š åˆå§‹åŒ–æ•°æ®é‡‡é›†åŠŸèƒ½...")
                # stdioæ¨¡å¼ä¸‹ä½¿ç”¨æ— å¤´æµè§ˆå™¨
                self.xhs_client.browser_manager.headless = True
                self.scheduler_initialized = self._initialize_data_collection()
            else:
                logger.info("â„¹ï¸ æ•°æ®é‡‡é›†åŠŸèƒ½æœªå¯ç”¨")
        except Exception as e:
            logger.warning(f"âš ï¸ æ•°æ®é‡‡é›†åŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {e}")

        # ä½¿ç”¨stdio transport
        logger.info("ğŸ¯ MCPå·¥å…·å·²æ³¨å†Œï¼Œç­‰å¾…å®¢æˆ·ç«¯è¿æ¥...")
        self.mcp.run(transport="stdio")

    def start(self) -> None:
        """å¯åŠ¨MCPæœåŠ¡å™¨"""
        logger.info("ğŸš€ å¯åŠ¨å°çº¢ä¹¦ MCP æœåŠ¡å™¨...")

        # è®¾ç½®æ—¥å¿—çº§åˆ«
        setup_logger(self.config.log_level)

        # éªŒè¯é…ç½®
        logger.info("ğŸ” éªŒè¯é…ç½®...")
        validation = self.config.validate_config()

        if not validation["valid"]:
            logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥:")
            for issue in validation["issues"]:
                logger.error(f"   â€¢ {issue}")
            logger.error("ğŸ’¡ è¯·æ£€æŸ¥ .env æ–‡ä»¶é…ç½®")
            return

        logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")

        # è®¾ç½®ä¿¡å·å¤„ç†
        self._setup_signal_handlers()

        # è·å–æœ¬æœºIPåœ°å€
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            s.connect(("10.254.254.254", 80))
            local_ip = s.getsockname()[0]
            s.close()
            logger.info(f"ğŸ“¡ æœ¬æœºIPåœ°å€: {local_ip}")
        except Exception:
            local_ip = "æœªçŸ¥"

        logger.info(f"ğŸš€ å¯åŠ¨SSEæœåŠ¡å™¨ (ç«¯å£{self.config.server_port})")
        logger.info("ğŸ“¡ å¯é€šè¿‡ä»¥ä¸‹åœ°å€è®¿é—®:")
        logger.info(f"   â€¢ http://localhost:{self.config.server_port}/sse (æœ¬æœº)")
        if local_ip != "æœªçŸ¥":
            logger.info(f"   â€¢ http://{local_ip}:{self.config.server_port}/sse (å†…ç½‘)")
            logger.info(f"   â€¢ http://{local_ip}:{self.config.server_port}/sse (Dockerå®¹å™¨è®¿é—®)")
        
        logger.info("ğŸ”§ åœ¨n8nä¸­é…ç½®:")
        if local_ip != "æœªçŸ¥":
            logger.info(f"   MCP Server URL: http://{local_ip}:{self.config.server_port}/sse")
        else:
            logger.info(f"   MCP Server URL: http://localhost:{self.config.server_port}/sse")

        logger.info("ğŸ¯ MCPå·¥å…·åˆ—è¡¨:")
        logger.info("   â€¢ test_connection - æµ‹è¯•MCPè¿æ¥")
        logger.info("   â€¢ smart_publish_note - å‘å¸ƒå°çº¢ä¹¦ç¬”è®°ï¼ˆæ”¯æŒæ™ºèƒ½è·¯å¾„è§£æï¼‰")
        logger.info("   â€¢ check_task_status - æ£€æŸ¥å‘å¸ƒä»»åŠ¡çŠ¶æ€")
        logger.info("   â€¢ get_task_result - è·å–å·²å®Œæˆä»»åŠ¡çš„ç»“æœ")
        logger.info("   â€¢ login_xiaohongshu - æ™ºèƒ½ç™»å½•å°çº¢ä¹¦")
        logger.info("   â€¢ get_creator_data_analysis - è·å–åˆ›ä½œè€…æ•°æ®ç”¨äºåˆ†æ")
        logger.info("   â€¢ parse_xiaohongshu_url - è§£æå°çº¢ä¹¦URLï¼Œæå–é¡µé¢å†…å®¹")
        logger.info("   â€¢ search_notes - æ ¹æ®å…³é”®è¯æœç´¢ç¬”è®°")
        logger.info("   â€¢ get_note_content - è·å–ç¬”è®°å†…å®¹ï¼ˆéœ€è¦xsec_tokenï¼‰")
        logger.info("   â€¢ get_note_comments - è·å–ç¬”è®°è¯„è®ºï¼ˆéœ€è¦xsec_tokenï¼‰")

        logger.info("ğŸ’¡ æ–°åŠŸèƒ½ä½¿ç”¨æµç¨‹:")
        logger.info("   1. search_notes('å…³é”®è¯') -> è·å–ç¬”è®°åˆ—è¡¨")
        logger.info("   2. ä»ç»“æœä¸­è·å–å¸¦xsec_tokençš„URL")
        logger.info("   3. get_note_content(url) -> è·å–è¯¦ç»†å†…å®¹")
        logger.info("   4. get_note_comments(url) -> è·å–è¯„è®ºåˆ—è¡¨")

        logger.info("ğŸ”§ æŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
        logger.info("ğŸ’¡ ç»ˆæ­¢æ—¶çš„ASGIé”™è¯¯ä¿¡æ¯æ˜¯æ­£å¸¸ç°è±¡ï¼Œå¯ä»¥å¿½ç•¥")

        # åˆå§‹åŒ–æ•°æ®é‡‡é›†åŠŸèƒ½ï¼ˆæ— å¤´æ¨¡å¼ï¼‰
        logger.info("ğŸ“Š åˆå§‹åŒ–æ•°æ®é‡‡é›†åŠŸèƒ½ï¼ˆæ— å¤´æ¨¡å¼ï¼‰...")
        try:
            asyncio.run(self._initialize_data_collection())
            if self.scheduler_initialized:
                logger.info("âœ… æ•°æ®é‡‡é›†åŠŸèƒ½åˆå§‹åŒ–å®Œæˆï¼ˆæ— å¤´æ¨¡å¼ï¼‰")
            else:
                logger.info("â„¹ï¸ æ•°æ®é‡‡é›†åŠŸèƒ½æœªå¯ç”¨æˆ–åˆå§‹åŒ–å¤±è´¥")
        except Exception as e:
            logger.warning(f"âš ï¸ æ•°æ®é‡‡é›†åŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {e}")

        try:
            # ä½¿ç”¨FastMCPå†…ç½®çš„runæ–¹æ³•ï¼Œç¦ç”¨uvicornçš„æ—¥å¿—ä»¥é¿å…å¹²æ‰°MCPé€šä¿¡
            import logging
            logging.getLogger("uvicorn").setLevel(logging.WARNING)
            logging.getLogger("uvicorn.access").setLevel(logging.WARNING)

            self.mcp.run(transport="sse", port=self.config.server_port, host=self.config.server_host)

        except KeyboardInterrupt:
            logger.info("ğŸ‘‹ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡å™¨...")
        except Exception as e:
            logger.error(f"âŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
            raise
        finally:
            # æ¸…ç†èµ„æº
            try:
                # åœæ­¢æ•°æ®é‡‡é›†è°ƒåº¦å™¨
                if self.scheduler_initialized and data_scheduler.is_running():
                    logger.info("ğŸ§¹ åœæ­¢æ•°æ®é‡‡é›†è°ƒåº¦å™¨...")
                    asyncio.run(data_scheduler.stop())

                # æ¸…ç†æµè§ˆå™¨å®ä¾‹
                if hasattr(self.xhs_client, 'browser_manager') and self.xhs_client.browser_manager.is_initialized:
                    logger.info("ğŸ§¹ æ¸…ç†æ®‹ç•™çš„æµè§ˆå™¨å®ä¾‹...")
                    self.xhs_client.browser_manager.close_driver()
            except Exception as cleanup_error:
                logger.warning(f"âš ï¸ æ¸…ç†èµ„æºæ—¶å‡ºé”™: {cleanup_error}")

            logger.info("âœ… æœåŠ¡å™¨å·²åœæ­¢")


# ä¾¿æ·å‡½æ•°
def create_mcp_server(config: XHSConfig) -> MCPServer:
    """
    åˆ›å»ºMCPæœåŠ¡å™¨çš„ä¾¿æ·å‡½æ•°
    
    Args:
        config: é…ç½®ç®¡ç†å™¨å®ä¾‹
        
    Returns:
        MCPæœåŠ¡å™¨å®ä¾‹
    """
    return MCPServer(config)


def main():
    """ä¸»å‡½æ•°å…¥å£"""
    import sys
    from ..core.config import XHSConfig

    config = XHSConfig()
    server = MCPServer(config)

    # æ£€æŸ¥æ˜¯å¦é€šè¿‡stdioå¯åŠ¨ï¼ˆClaude Desktopä½¿ç”¨ï¼‰
    if len(sys.argv) > 1 and sys.argv[1] == "--stdio":
        # ä½¿ç”¨stdioæ¨¡å¼
        server.start_stdio()
    else:
        # é»˜è®¤ä½¿ç”¨SSEæ¨¡å¼ï¼ˆç”¨äºå…¶ä»–å®¢æˆ·ç«¯ï¼‰
        server.start()


if __name__ == "__main__":
    main() 